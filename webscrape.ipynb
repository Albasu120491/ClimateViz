{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Copernicus climate indicators graphic and metadata\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "# download an image\n",
        "def download_image(image_url, folder_path, filename):\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        with open(file_path, 'wb') as out_file:\n",
        "            shutil.copyfileobj(response.raw, out_file)\n",
        "    del response\n",
        "\n",
        "# clean up the description\n",
        "def clean_description(description):\n",
        "    description = re.sub(r'HIGH-RESOLUTION IMAGE', '', description).strip()\n",
        "    return description\n",
        "\n",
        "# extract key messages from each indicator page\n",
        "def extract_key_messages(soup):\n",
        "    key_messages_div = soup.find('div', class_='key--messages')\n",
        "    if key_messages_div:\n",
        "        key_messages_list = key_messages_div.find_all('li')\n",
        "        key_messages = ' | '.join([li.text.strip() for li in key_messages_list])\n",
        "        return key_messages\n",
        "    return 'No key messages'\n",
        "\n",
        "# base URL\n",
        "base_url = 'https://climate.copernicus.eu'\n",
        "\n",
        "# each climate indicator url\n",
        "indicator_urls = {\n",
        "    'Temperature': 'https://climate.copernicus.eu/climate-indicators/temperature',\n",
        "    'Sea level': 'https://climate.copernicus.eu/climate-indicators/sea-level',\n",
        "    'Greenhouse gas concentrations': 'https://climate.copernicus.eu/climate-indicators/greenhouse-gas-concentrations',\n",
        "    'Greenhouse gas fluxes': 'https://climate.copernicus.eu/climate-indicators/greenhouse-gas-fluxes',\n",
        "    'Glaciers': 'https://climate.copernicus.eu/climate-indicators/glaciers',\n",
        "    'Ice sheets': 'https://climate.copernicus.eu/climate-indicators/ice-sheets',\n",
        "    'Sea ice': 'https://climate.copernicus.eu/climate-indicators/sea-ice',\n",
        "    'Sea surface temperature': 'https://climate.copernicus.eu/climate-indicators/sea-surface-temperature'\n",
        "}\n",
        "\n",
        "image_folder = 'downloaded_images'\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for indicator_name, url in indicator_urls.items():\n",
        "    response = requests.get(url)\n",
        "    response.encoding = 'utf-8'\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        key_messages = extract_key_messages(soup)\n",
        "\n",
        "        for tab_content in soup.find_all('div', class_='paragraph--type--tab'):\n",
        "            tab_title = tab_content.find('h3').text if tab_content.find('h3') else 'No Title'\n",
        "            img_tag = tab_content.find('img', class_='align-center')\n",
        "            if img_tag:\n",
        "                relative_image_url = img_tag.get('src', '')\n",
        "                absolute_image_url = base_url + relative_image_url\n",
        "                image_filename = os.path.basename(relative_image_url)\n",
        "                download_image(absolute_image_url, image_folder, image_filename)\n",
        "                local_image_path = os.path.join(image_folder, image_filename)\n",
        "                description_tag = img_tag.find_next('p')\n",
        "                description = clean_description(description_tag.text) if description_tag else 'No Description'\n",
        "                all_data.append([indicator_name, tab_title, local_image_path, description, key_messages])\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data for {indicator_name}\")\n",
        "\n",
        "df = pd.DataFrame(all_data, columns=['Indicator', 'Tab Title', 'Local Image Path', 'Description', 'Key Messages'])\n",
        "df.to_csv('climate_indicators_with_images.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "# zip file as it would be v time-consuming to download the full folder\n",
        "shutil.make_archive(image_folder, 'zip', image_folder)\n",
        "\n",
        "\n",
        "files.download(image_folder + '.zip')\n",
        "from google.colab import files\n",
        "files.download('climate_indicators_with_images.csv')\n",
        "\n",
        "print(\"Data scraped, images downloaded and compressed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hSpYN2vfej9o",
        "outputId": "178324e4-e17b-4151-9473-fa864ef179bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ca433226-5dde-442f-8f61-94e526bf702a\", \"downloaded_images.zip\", 17733084)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data scraped, images downloaded and compressed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('climate_reports_images.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "3NnysH6Sns8x",
        "outputId": "11d09944-dd93-4293-f47d-9db89b9edaf5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: climate_reports_images.csv",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e4af0e5555db>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'climate_reports_images.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: climate_reports_images.csv"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "\n",
        "def download_image(url, folder, filename):\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(os.path.join(folder, filename), 'wb') as out_file:\n",
        "        shutil.copyfileobj(response.raw, out_file)\n",
        "    del response\n",
        "\n",
        "\n",
        "def clean_description(description):\n",
        "    return ' '.join(description.split())\n",
        "\n",
        "\n",
        "base_url = 'https://climate.copernicus.eu'\n",
        "\n",
        "# URL for the \"Global Climate Highlights 2023\" page\n",
        "page_url = 'https://climate.copernicus.eu/global-climate-highlights-2023'\n",
        "\n",
        "\n",
        "image_folder = 'downloaded_images'\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "response = requests.get(page_url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "\n",
        "all_data = []\n",
        "\n",
        "\n",
        "for section in soup.find_all('div', class_='paragraph--type--tab'):\n",
        "    tab_title = section.find('h2', class_='ccl-block-title').get_text(strip=True) if section.find('h2', class_='ccl-block-title') else 'No Title'\n",
        "    img_tag = section.find('img')\n",
        "    key_messages_tag = section.find('div', class_='key--messages')\n",
        "\n",
        "    if img_tag:\n",
        "        relative_image_url = img_tag.get('src')\n",
        "        absolute_image_url = urljoin(base_url, relative_image_url)\n",
        "        image_filename = os.path.basename(relative_image_url)\n",
        "        download_image(absolute_image_url, image_folder, image_filename)\n",
        "        local_image_path = os.path.join(image_folder, image_filename)\n",
        "\n",
        "        description_tag = img_tag.find_next('p')\n",
        "        description = clean_description(description_tag.get_text()) if description_tag else 'No Description'\n",
        "\n",
        "        key_messages = clean_description(key_messages_tag.get_text()) if key_messages_tag else 'No Key Messages'\n",
        "\n",
        "        all_data.append([tab_title, local_image_path, description, key_messages])\n",
        "\n",
        "\n",
        "df = pd.DataFrame(all_data, columns=['Tab Title', 'Local Image Path', 'Description', 'Key Messages'])\n",
        "csv_file = 'global_climate_highlights_2023.csv'\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n",
        "# Compress the downloaded images folder\n",
        "shutil.make_archive(image_folder, 'zip', image_folder)\n",
        "files.download(image_folder + '.zip')\n",
        "from google.colab import files\n",
        "files.download('global_climate_highlights_2023.csv')\n",
        "print(f\"Data scraped and saved to {csv_file}. Images downloaded and compressed in {image_folder}.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MqEGU6uvngo2",
        "outputId": "9186ebc2-940b-4ce6-d765-6658b6a41399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_719d63d8-1d99-4a7a-b690-4343e7816059\", \"downloaded_images.zip\", 28579272)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ef06c41-32eb-4c79-bcc7-caf1f63f8b92\", \"global_climate_highlights_2023.csv\", 2168)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data scraped and saved to global_climate_highlights_2023.csv. Images downloaded and compressed in downloaded_images.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenation of text + graphics\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xC_Vt6oUWYh",
        "outputId": "7215623e-479f-44cb-b7d7-99f0fdc5a794"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import textwrap\n",
        "\n",
        "# CSV file and base directory paths\n",
        "csv_file_path = '/content/drive/MyDrive/zooniverse/zooniverse_modified.csv'\n",
        "base_dir = '/content/drive/MyDrive/zooniverse/'\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Adding prefixes to Task 2 and Task 3 texts directly in the DataFrame\n",
        "df['Task 2'] = 'Q2: ' + df['Task 2'].astype(str)\n",
        "df['Task 3'] = 'Q3: ' + df['Task 3'].astype(str)\n",
        "\n",
        "# Concatenate task texts with explicit line breaks\n",
        "df['All_Tasks'] = df[['Task 1', 'Task 2', 'Task 3']].apply(lambda x: '\\n'.join(x), axis=1)\n",
        "\n",
        "# Create output directory\n",
        "output_dir = os.path.join(base_dir, 'All_Tasks_Images')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def add_text_to_image(image_path, text, output_path, initial_font_size, min_font_size):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Could not read image: {image_path}\")\n",
        "        return\n",
        "    original_height, original_width = image.shape[:2]\n",
        "\n",
        "    # Calculate the optimal font size and scale factor\n",
        "    scale_factor = max(original_width, original_height) / 1024\n",
        "    font_size = max(int(initial_font_size * scale_factor), min_font_size)\n",
        "    font_scale = font_size / 48\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    thickness = 5  # Increased thickness for darker text\n",
        "    color = (0, 0, 0)  # Black color\n",
        "    margin = int(30 * scale_factor)\n",
        "\n",
        "    # Split text into lines considering explicit line breaks\n",
        "    lines = text.split('\\n')\n",
        "    wrap_width = max(int(original_width / (font_size / 2)), 10)\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        wrapped_lines.extend(textwrap.wrap(line, width=wrap_width))\n",
        "\n",
        "    # Adjust text box height based on wrapped lines\n",
        "    text_box_height = len(wrapped_lines) * (font_size + int(20 * scale_factor))\n",
        "\n",
        "    # Adjust canvas height to fit wrapped text\n",
        "    canvas_height = original_height + text_box_height + 2 * margin\n",
        "\n",
        "    # Create expanded canvas\n",
        "    canvas = np.ones((canvas_height, original_width, 3), dtype=np.uint8) * 255\n",
        "    canvas[canvas_height-original_height:, 0:original_width] = image\n",
        "\n",
        "    # Add wrapped text on the canvas\n",
        "    y_offset = margin\n",
        "    for line in wrapped_lines:\n",
        "        text_size = cv2.getTextSize(line, font, font_scale, thickness)[0]\n",
        "        text_x = (original_width - text_size[0]) // 2\n",
        "        cv2.putText(canvas, line, (text_x, y_offset), font, font_scale, color, thickness)\n",
        "        y_offset += font_size + int(20 * scale_factor)\n",
        "\n",
        "    # Save the modified image\n",
        "    cv2.imwrite(output_path, canvas)\n",
        "    print(f\"Image saved: {output_path}\")\n",
        "\n",
        "# Process each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    image_path = row['Image Path']  # Ensure this matches your actual column name\n",
        "    if not isinstance(image_path, str): continue\n",
        "    image_name = os.path.basename(image_path)\n",
        "    original_image_path = os.path.join(base_dir, image_path)\n",
        "    all_tasks_text = row['All_Tasks']\n",
        "    output_image_path = os.path.join(output_dir, image_name)\n",
        "    add_text_to_image(original_image_path, all_tasks_text, output_image_path, initial_font_size, min_font_size)\n",
        "\n",
        "print(\"All images have been processed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekRAgjf1egZC",
        "outputId": "bea8cbfc-9840-4746-da52-6add34e0a932"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_1_INDICATOR_TEMPERATURE.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_2_INDICATOR_TEMPERATURE.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_3_INDICATOR_TEMPERATURE.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_4_INDICATOR_TEMPERATURE.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_1_INDICATOR_SEA_LEVEL.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_2_INDICATOR_SEA_LEVEL.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHG_CONC_Fig1.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHG_CONC_Fig4.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHGFlux_Fig2.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHGFlux_Fig3.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHGFlux_Fig4.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_1_glaciers_indicator_global_MB.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_2_glaciers_indicator_regional_MB.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_3_glaciers_indicator_reference_map.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_1_ice_sheets_indicator_greenland-01.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_2_ice_sheets_indicator_antarctica-01.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_S1_ARCTIC_MAP.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_S1_ANTARCTICA_MAP.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_1_sst_indicator_global_time_series.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_3_sst_indicator_european_seas.png\n",
            "Image saved: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_5_sst_indicator_nino3.4.png\n",
            "All images have been processed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Directory containing the images to resize\n",
        "image_dir = '/content/drive/MyDrive/zooniverse/All_Tasks_Images'\n",
        "\n",
        "# Scale factor (0 < scale < 1 to reduce size)\n",
        "scale_factor = 0.5  # Adjust as needed to decrease the image size\n",
        "\n",
        "# Iterate over each file in the directory\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        # Read the image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Skip files that aren't images\n",
        "        if image is None:\n",
        "            continue\n",
        "\n",
        "        # Calculate new dimensions\n",
        "        new_width = int(image.shape[1] * scale_factor)\n",
        "        new_height = int(image.shape[0] * scale_factor)\n",
        "        new_dimensions = (new_width, new_height)\n",
        "\n",
        "        # Resize the image\n",
        "        resized_image = cv2.resize(image, new_dimensions, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # Overwrite the original image\n",
        "        cv2.imwrite(image_path, resized_image)\n",
        "        print(f\"Resized and overwritten: {image_path}\")\n",
        "\n",
        "print(\"All images resized and overwritten successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U01tMsb4O5S9",
        "outputId": "587a77bb-1662-43cf-e24d-eb8e4f6322ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_1_INDICATOR_TEMPERATURE.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_2_INDICATOR_TEMPERATURE.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_3_INDICATOR_TEMPERATURE.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_4_INDICATOR_TEMPERATURE.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_1_INDICATOR_SEA_LEVEL.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_2_INDICATOR_SEA_LEVEL.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHG_CONC_Fig1.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHG_CONC_Fig4.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHGFlux_Fig2.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHGFlux_Fig3.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/C3S_ESOTC2022_INDICATORS_GHGFlux_Fig4.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_1_glaciers_indicator_global_MB.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_2_glaciers_indicator_regional_MB.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_3_glaciers_indicator_reference_map.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_1_ice_sheets_indicator_greenland-01.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_2_ice_sheets_indicator_antarctica-01.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_S1_ARCTIC_MAP.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/FIGURE_S1_ANTARCTICA_MAP.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_1_sst_indicator_global_time_series.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_3_sst_indicator_european_seas.png\n",
            "Resized and overwritten: /content/drive/MyDrive/zooniverse/All_Tasks_Images/Figure_5_sst_indicator_nino3.4.png\n",
            "All images resized and overwritten successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q37aENc6UwYL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}