# -*- coding: utf-8 -*-
"""Fewshot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hCeQoqckoZyslbJy8Bjdejq1PqJ4WEOI
"""

# gemini_fewshot_multitask_table.py

import pandas as pd
import os
import json
from PIL import Image
import base64
from io import BytesIO
from tqdm import tqdm
import re
from openai import OpenAI



# File paths
csv_path = ""
table_path = ""
image_root_dir = ""
output_csv = ""
log_dir = ""
os.makedirs(log_dir, exist_ok=True)

def encode_image_base64(image_path):
    with Image.open(image_path) as img:
        buffered = BytesIO()
        img.convert("RGB").save(buffered, format="JPEG")
        return base64.b64encode(buffered.getvalue()).decode("utf-8")

def normalize_filename(name):
    if not isinstance(name, str):
        return ""
    return re.sub(r'[^a-z0-9]+', '_', name.lower().strip())

def find_image_path(root_dir, base_filename):
    normalized_target = normalize_filename(base_filename)
    for dirpath, _, filenames in os.walk(root_dir):
        for file in filenames:
            if normalize_filename(os.path.splitext(file)[0]) == normalized_target:
                return os.path.join(dirpath, file)
    return None

def extract_json_block(text):
    stack, start, blocks = [], None, []
    for i, char in enumerate(text):
        if char == '{':
            if not stack: start = i
            stack.append(char)
        elif char == '}' and stack:
            stack.pop()
            if not stack and start is not None:
                blocks.append(text[start:i+1])
                start = None
    return blocks[0] if blocks else None

def build_prompt(generated_fact, table_text, chart_title, chart_type, chart_source, fewshot_examples):
    intro = f"""You are given a climate-related chart, a table extracted from it, and a generated fact. Perform two tasks:

First, extract a structured JSON with this schema:
{{
  "title": "...",
  "type": "...",
  "source": "...",
  "facts": [{{ "subject": "...", "subject_type": "...", "attribute": "...", "attribute_type": "...", "value": "...", "value_range": {{"min": "...", "max": "..."}}, "unit": "...", "time_range": "...", "temporal_granularity": "...", "relation": "...", "trend": "...", "reference_frame": "...", "uncertainty": "..." }}]
}}

Second, determine whether the fact is:
- Supported by the chart and table
- Refuted by the chart and table
- Not Enough Information (NEI)

Respond in this format:

### JSON Extraction:
<your JSON>

### Fact-Checking Label:
<support/refute/NEI>
"""

    shots = ""
    for shot in fewshot_examples:
        shots += f"""

Generated Fact: {shot['fact']}

Table:
{shot['table'].strip()[:500]}... [truncated]

### JSON Extraction:
<example omitted>

### Fact-Checking Label:
{shot['label']}
"""

    test_case = f"""

Generated Fact: {generated_fact}

Table:
{table_text.strip()[:700]}... [truncated]
"""

    return intro + shots + test_case


df = pd.read_csv(csv_path)
df_table = pd.read_csv(table_path)
df = df.dropna(subset=['annotated_title'])
df_table = df_table.dropna(subset=['annotated_title'])
df['normalized_title'] = df['annotated_title'].apply(normalize_filename)
df_table['normalized_title'] = df_table['annotated_title'].apply(normalize_filename)
df_merged = pd.merge(df, df_table[['normalized_title', 'table']], on='normalized_title', how='left')
df_test = df_merged.copy()


fewshot_examples = []
seen_labels = set()
for _, row in df_merged.iterrows():
    label = str(row.get("label", "")).strip().lower()
    if label in ["support", "refute"] and label not in seen_labels:
        fewshot_examples.append({
            "fact": row["generated fact"],
            "table": row.get("table", ""),
            "label": label
        })
        seen_labels.add(label)
    if len(fewshot_examples) == 2:
        break

predicted_labels = []
extracted_explanations = []


for idx, row in tqdm(df_test.iterrows(), total=len(df_test)):
    try:
        filename = row["annotated_title"]
        chart_path = find_image_path(image_root_dir, filename)

        if chart_path is None:
            print(f"[{idx}] Image not found: {filename}")
            predicted_labels.append("image_not_found")
            extracted_explanations.append(None)
            continue

        generated_fact = row["generated fact"]
        chart_title = row.get("title", filename)
        chart_type = row.get("type", "unknown")
        chart_source = row.get("source", "unknown")
        table_text = row.get("table", "")
        base64_image = encode_image_base64(chart_path)

        prompt = build_prompt(generated_fact, table_text, chart_title, chart_type, chart_source, fewshot_examples)

        messages = [
            {
                "role": "system",
                "content": "You are a helpful assistant skilled in scientific chart analysis, fact-checking, and JSON structuring."
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]
            }
        ]

        response = client.chat.completions.create(
            model="google/gemini-2.5-flash-preview",
            messages=messages,
            extra_headers={
                "HTTP-Referer": "https://your-site.com",
                "X-Title": "ClimateViz"
            },
            max_tokens=1200,
            temperature=0
        )

        output = response.choices[0].message.content.strip()
        print(f"[{idx}] Output: {repr(output)}")

        # Save raw output
        with open(os.path.join(log_dir, f"gemini_output_{idx}.txt"), "w") as f:
            f.write(output)

        # Early sanity check
        if not output.lower().strip().startswith("### json extraction:"):
            print(f"[{idx}] Warning: Unexpected format. Skipping.")
            predicted_labels.append("bad_format")
            extracted_explanations.append(None)
            continue

        # Try extracting JSON
        json_match = re.search(r'### JSON Extraction:\s*(?:```json)?\s*(\{.*?\})\s*(?:```)?\s*### Fact-Checking Label:', output, re.DOTALL)
        if not json_match:
            json_match = re.search(r'### JSON Extraction:\s*(\{.*?\})', output, re.DOTALL)

        if json_match:
            explanation_json = json.loads(json_match.group(1))
            extracted_explanations.append(json.dumps(explanation_json, ensure_ascii=False))
        else:
            fallback_json = extract_json_block(output)
            if fallback_json:
                explanation_json = json.loads(fallback_json)
                extracted_explanations.append(json.dumps(explanation_json, ensure_ascii=False))
            else:
                print(f"[{idx}] Could not find JSON block.")
                extracted_explanations.append(None)
                predicted_labels.append("parse_error")
                continue


        label_match = re.search(r'### Fact-Checking Label:\s*(support|refute|nei)', output, re.IGNORECASE)
        if label_match:
            label = label_match.group(1).lower()
            predicted_labels.append(label if label != "nei" else "NEI")
        else:
            predicted_labels.append("unclear")

    except Exception as e:
        print(f"[{idx}] Error: {e}")
        predicted_labels.append(f"error: {str(e)}")
        extracted_explanations.append(None)

# Save
df_test["predicted_label"] = predicted_labels
df_test["explanation"] = extracted_explanations
df_test.to_csv(output_csv, index=False)
print(f" Saved predictions to {output_csv}")

#gemini_multitask_fewshot
import pandas as pd
import os
import json
from PIL import Image
import base64
from io import BytesIO
from tqdm import tqdm
import re
from openai import OpenAI


def encode_image_base64(image_path):
    with Image.open(image_path) as img:
        buffered = BytesIO()
        img.convert("RGB").save(buffered, format="JPEG")
        return base64.b64encode(buffered.getvalue()).decode("utf-8")

def normalize_filename(name):
    return re.sub(r'[^a-z0-9]+', '_', name.lower().strip()) if isinstance(name, str) else ""

def find_image_path(root_dir, base_filename):
    normalized_target = normalize_filename(base_filename)
    for dirpath, _, filenames in os.walk(root_dir):
        for file in filenames:
            if normalize_filename(os.path.splitext(file)[0]) == normalized_target:
                return os.path.join(dirpath, file)
    return None

def extract_json_block(text):
    stack, start, blocks = [], None, []
    for i, char in enumerate(text):
        if char == '{':
            if not stack: start = i
            stack.append(char)
        elif char == '}' and stack:
            stack.pop()
            if not stack and start is not None:
                blocks.append(text[start:i+1])
                start = None
    return blocks[0] if blocks else None

def build_prompt(generated_fact, chart_title, chart_type, chart_source, fewshot_examples):
    intro = f"""You are given a climate-related chart and a generated fact. Perform two tasks:

First, extract a structured JSON using this schema:
{{
  "title": "...",
  "type": "...",
  "source": "...",
  "facts": [{{ "subject": "...", "subject_type": "...", "attribute": "...", "attribute_type": "...", "value": "...", "value_range": {{"min": "...", "max": "..."}}, "unit": "...", "time_range": "...", "temporal_granularity": "...", "relation": "...", "trend": "...", "reference_frame": "...", "uncertainty": "..." }}]
}}

Second, determine whether the fact is:
- Supported by the chart
- Refuted by the chart
- Not Enough Information (NEI)

Respond in this format:

### JSON Extraction:
<your JSON>

### Fact-Checking Label:
<support/refute/NEI>
"""
    fewshots = ""
    for ex in fewshot_examples:
        fewshots += f"""
Generated Fact: {ex['fact']}
### JSON Extraction:
<example omitted>
### Fact-Checking Label:
{ex['label']}
"""
    test = f"""
Generated Fact: {generated_fact}
"""
    return intro + fewshots + test


df = pd.read_csv(csv_path)
df = df.dropna(subset=["annotated_title", "generated fact"])
df["normalized_title"] = df["annotated_title"].apply(normalize_filename)


fewshot_examples = []
seen = set()
for _, row in df.iterrows():
    lbl = str(row.get("label", "")).lower()
    if lbl in ["support", "refute"] and lbl not in seen:
        fewshot_examples.append({"fact": row["generated fact"], "label": lbl})
        seen.add(lbl)
    if len(fewshot_examples) == 2:
        break

df_test = df.copy()
predicted_labels = []
extracted_explanations = []


for idx, row in tqdm(df_test.iterrows(), total=len(df_test)):
    try:
        filename = row["annotated_title"]
        chart_path = find_image_path(image_root_dir, filename)
        if not chart_path:
            print(f"[{idx}] Image not found: {filename}")
            predicted_labels.append("image_not_found")
            extracted_explanations.append(None)
            continue

        base64_img = encode_image_base64(chart_path)
        generated_fact = row["generated fact"]
        chart_title = row.get("title", filename)
        chart_type = row.get("type", "unknown")
        chart_source = row.get("source", "unknown")

        prompt = build_prompt(generated_fact, chart_title, chart_type, chart_source, fewshot_examples)

        messages = [
            {"role": "system", "content": "You are a helpful assistant skilled in scientific chart analysis and fact verification."},
            {"role": "user", "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}}
            ]}
        ]

        response = client.chat.completions.create(
            model="google/gemini-2.5-flash-preview",
            messages=messages,
            max_tokens=800,
            temperature=0,
            extra_headers={
                "HTTP-Referer": "https://your-site.com",
                "X-Title": "ClimateViz"
            }
        )

        output = response.choices[0].message.content.strip()
        print(f"[{idx}] Output: {repr(output[:200])}")


        json_match = re.search(r'### JSON Extraction:\s*```json\s*(\{.*?\})\s*```', output, re.DOTALL)
        if not json_match:
            json_match = re.search(r'### JSON Extraction:\s*(\{.*?\})\s*### Fact-Checking Label:', output, re.DOTALL)

        if json_match:
            try:
                explanation_json = json.loads(json_match.group(1))
                extracted_explanations.append(json.dumps(explanation_json, ensure_ascii=False))
            except:
                extracted_explanations.append(None)
        else:
            fallback_json = extract_json_block(output)
            if fallback_json:
                try:
                    explanation_json = json.loads(fallback_json)
                    extracted_explanations.append(json.dumps(explanation_json, ensure_ascii=False))
                except:
                    extracted_explanations.append(None)
            else:
                extracted_explanations.append(None)


        label_match = re.search(r'### Fact-Checking Label:\s*(support|refute|nei)', output, re.IGNORECASE)
        label = label_match.group(1).lower() if label_match else "unclear"
        predicted_labels.append("NEI" if label == "nei" else label)

    except Exception as e:
        print(f"[{idx}] Error: {e}")
        predicted_labels.append(f"error: {str(e)}")
        extracted_explanations.append(None)


df_test["predicted_label"] = predicted_labels
df_test["explanation"] = extracted_explanations
df_test.to_csv(output_csv, index=False)
print(f"Saved predictions to {output_csv}")