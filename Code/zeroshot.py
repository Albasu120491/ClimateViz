# -*- coding: utf-8 -*-
"""zeroshot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rahk7MRn0hrupdUCIjLBU7fl2XbDabwj
"""

#zero-shot CT
import pandas as pd
import os
from PIL import Image
import base64
from io import BytesIO
from tqdm import tqdm
from openai import OpenAI
import re


# encode image to base64
def encode_image_base64(image_path):
    ext = os.path.splitext(image_path)[1].lower()
    mime = "image/jpeg" if ext in [".jpg", ".jpeg"] else "image/png"
    with Image.open(image_path) as img:
        buffered = BytesIO()
        img.convert("RGB").save(buffered, format="JPEG" if mime == "image/jpeg" else "PNG")
        return base64.b64encode(buffered.getvalue()).decode("utf-8"), mime

def normalize_filename(name):
    name = name.lower().strip()
    name = re.sub(r'[^a-z0-9]+', '_', name)
    return name


def find_image_path(root_dir, base_filename):
    normalized_target = normalize_filename(base_filename)
    possible_exts = [".png", ".jpg", ".jpeg"]
    for dirpath, _, filenames in os.walk(root_dir):
        for file in filenames:
            file_no_ext, ext = os.path.splitext(file)
            if ext.lower() in possible_exts:
                if normalize_filename(file_no_ext) == normalized_target:
                    return os.path.join(dirpath, file)
    return None


def build_messages(generated_fact, base64_image, mime_type):
    return [
        {
            "role": "system",
            "content": "You are a helpful fact-checking assistant."
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": f"""You are given a chart and a generated climate-related fact, based on the chart, determine whether the fact is:
- Supported by the chart
- Refuted by the chart
- Not Enough Information (NEI) to decide

Respond with only: "support", "refute", or "NEI".

Fact: {generated_fact}
"""
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{mime_type};base64,{base64_image}"
                    }
                }
            ]
        }
    ]

# Load dataset
df = pd.read_csv(csv_path)
df_test = df.copy()
predicted_labels = []


for idx, row in tqdm(df_test.iterrows(), total=len(df_test)):
    try:
        filename = row["annotated_title"].strip()
        chart_path = find_image_path(image_root_dir, filename)

        if chart_path is None:
            print(f"[{idx}] Image not found: {filename}")
            predicted_labels.append("image_not_found")
            continue

        generated_fact = row["generated fact"]
        base64_image, mime_type = encode_image_base64(chart_path)
        messages = build_messages(generated_fact, base64_image, mime_type)

        response = client.chat.completions.create(
            model="o3",
            messages=messages,
            max_completion_tokens=3000,
            temperature=1
        )

        output = response.choices[0].message.content.strip()
        print(f"[{idx}] Raw model output: {repr(output)}")

        output_clean = output.lower().strip()

        # Normalize output
        if output_clean == "support":
            label = "support"
        elif output_clean == "refute":
            label = "refute"
        elif output_clean == "nei":
            label = "NEI"
        elif "not enough" in output_clean or "insufficient" in output_clean:
            label = "NEI"
        elif "support" in output_clean:
            label = "support"
        elif "refute" in output_clean:
            label = "refute"
        elif "nei" in output_clean:
            label = "NEI"
        else:
            label = "unclear"

        predicted_labels.append(label)

    except Exception as e:
        print(f"[{idx}] Error processing row: {e}")
        predicted_labels.append(f"error: {str(e)}")


df_test["predicted_label"] = predicted_labels
df_test.to_csv(output_csv, index=False)
print(f"Labeled output saved to: {output_csv}")

# zeroshot CTT

import pandas as pd
import os
from PIL import Image
import base64
from io import BytesIO
from tqdm import tqdm
import re
import google.generativeai as genai


def encode_image_base64(image_path):
    ext = os.path.splitext(image_path)[1].lower()
    mime = "image/jpeg" if ext in [".jpg", ".jpeg"] else "image/png"
    with Image.open(image_path) as img:
        buffered = BytesIO()
        img.convert("RGB").save(buffered, format="JPEG" if mime == "image/jpeg" else "PNG")
        return base64.b64encode(buffered.getvalue()).decode("utf-8"), mime

def normalize_filename(name):
    if not isinstance(name, str):
        return ""
    return re.sub(r'[^a-z0-9]+', '_', name.lower().strip())

def find_image_path(root_dir, base_filename):
    normalized_target = normalize_filename(base_filename)
    for dirpath, _, filenames in os.walk(root_dir):
        for file in filenames:
            file_no_ext, ext = os.path.splitext(file)
            if ext.lower() in [".png", ".jpg", ".jpeg"]:
                if normalize_filename(file_no_ext) == normalized_target:
                    return os.path.join(dirpath, file)
    return None


def build_prompt(fact, table_text):
    return f"""
You are given a chart, a table extracted from it, and a generated climate-related fact. Determine whether the fact is:
- Supported by the chart and table
- Refuted by the chart and table
- Not Enough Information (NEI) to decide

Respond with only one of the following: support, refute, or NEI.

Fact: {fact}

Table:
{table_text.strip()[:1000]}
"""


df = pd.read_csv(csv_path)
df_table = pd.read_csv(table_path)
df['normalized_title'] = df['annotated_title'].apply(normalize_filename)
df_table['normalized_title'] = df_table['annotated_title'].apply(normalize_filename)
df_merged = pd.merge(df, df_table[['normalized_title', 'table']], on='normalized_title', how='left')
df_test = df_merged.copy()

predicted_labels = []

for idx, row in tqdm(df_test.iterrows(), total=len(df_test)):
    try:
        filename = row['annotated_title'].strip()
        chart_path = find_image_path(image_root_dir, filename)

        if chart_path is None:
            print(f"[{idx}] Image not found: {filename}")
            predicted_labels.append("image_not_found")
            continue

        fact = row["generated fact"]
        table_text = row.get("table", "")
        prompt = build_prompt(fact, table_text)
        with open(chart_path, "rb") as f:
            image_bytes = f.read()

        response = model.generate_content(
            contents=[
                {"role": "user", "parts": [
                    {"text": prompt},
                    {"inline_data": {"mime_type": "image/png", "data": image_bytes}}
                ]}
            ]
        )

        output = response.text.strip()
        print(f"[{idx}] Raw model output: {repr(output)}")

        output_clean = output.lower().strip()
        if output_clean == "support":
            label = "support"
        elif output_clean == "refute":
            label = "refute"
        elif output_clean == "nei":
            label = "NEI"
        elif "not enough" in output_clean or "insufficient" in output_clean:
            label = "NEI"
        elif "support" in output_clean:
            label = "support"
        elif "refute" in output_clean:
            label = "refute"
        elif "nei" in output_clean:
            label = "NEI"
        else:
            label = "unclear"

        predicted_labels.append(label)

    except Exception as e:
        print(f"[{idx}] Error: {e}")
        predicted_labels.append(f"error: {str(e)}")

df_test["predicted_label"] = predicted_labels
df_test.to_csv(output_csv, index=False)
print(f"Saved predictions to {output_csv}")